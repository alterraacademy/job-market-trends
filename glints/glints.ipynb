{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posted_date: Job DescriptionsMembangun perangkat lunak yang kuat dan skalabel dengan membangun fitur baru, debugging, dan mengoptimalkan aplikasiMenulis kode bersih untuk mengembangkan aplikasi web fungsionalBerkolaborasi dengan pengembang front-end untuk mengintegrasikan elemen yang terlihat oleh pengguna dengan logika sisi serverMengembangkan dan mengusulkan produk atau fitur baru dengan memantau industriBekerja sama dengan desainer, manajer produk, dan administrator sistem untuk mengidentifikasi dan membangun fitur baruJob RequirementsPendidikan minimal S1 Ilmu komputer / Sistem Informasi / Informasi teknologiPengalaman minimal 1 tahun di bidang yang samaPengetahuan dan pengalaman yang kuat dalam back-end (Python / PHP / Go)Familiaritas dengan database seperti MySQL, MongoDBPengalaman dengan Ubuntu dan manajemen serverPengalaman dengan DevOps dan CI/CDKeahlian dalam penggunaan alat manajemen kode seperti GitFamiliar dengan layanan web hosting seperti GCP, AWS, AzurePengetahuan tentang arsitektur MVC, Pub/Sub, dan Streams\n",
      "Job Title: Back End Developer\n",
      "Company Name: PT Rect Media Komputindo\n",
      "Experience: 1 â€“ 3 tahun\n",
      "Education: Minimal Sarjana (S1)\n",
      "Work Place: Kerja di kantor\n",
      "Work Type: full_time\n",
      "Salary: Rp3jt-Rp5jt\n",
      "Detail Description: Job DescriptionsMembangun perangkat lunak yang kuat dan skalabel dengan membangun fitur baru, debugging, dan mengoptimalkan aplikasiMenulis kode bersih untuk mengembangkan aplikasi web fungsionalBerkolaborasi dengan pengembang front-end untuk mengintegrasikan elemen yang terlihat oleh pengguna dengan logika sisi serverMengembangkan dan mengusulkan produk atau fitur baru dengan memantau industriBekerja sama dengan desainer, manajer produk, dan administrator sistem untuk mengidentifikasi dan membangun fitur baruJob RequirementsPendidikan minimal S1 Ilmu komputer / Sistem Informasi / Informasi teknologiPengalaman minimal 1 tahun di bidang yang samaPengetahuan dan pengalaman yang kuat dalam back-end (Python / PHP / Go)Familiaritas dengan database seperti MySQL, MongoDBPengalaman dengan Ubuntu dan manajemen serverPengalaman dengan DevOps dan CI/CDKeahlian dalam penggunaan alat manajemen kode seperti GitFamiliar dengan layanan web hosting seperti GCP, AWS, AzurePengetahuan tentang arsitektur MVC, Pub/Sub, dan Streams\n",
      "No more pages to fetch\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Helper Function\n",
    "def find_tag_value(soup, tag, class_name):\n",
    "    try:\n",
    "        return soup.find(tag, class_=(class_name)).text.strip()\n",
    "    except AttributeError:\n",
    "        return None\n",
    "    \n",
    "def find_tag_attr(job_card, attr):\n",
    "    try:\n",
    "        return job_card.find('div', {'data-gtm-job-' + attr: True})['data-gtm-job-' + attr]\n",
    "    except (AttributeError, KeyError):\n",
    "        return None\n",
    "    \n",
    "\n",
    "list_jobs = {'golang','.net','php developer','laravel','java','python','nodejs','reactjs','nextjs','angularjs','fluter','kotlin','vuejs','backend','frontend','mobile','data analyst','data scientist','data engineer','software engineer','software developer','full-stack','programmer','javascript','user interface','user experience','hr officer','accounting officer'}\n",
    "\n",
    "# list_jobs = {'golang'}\n",
    "\n",
    "page = 1\n",
    "data = []\n",
    "\n",
    "for i in list_jobs:\n",
    "    search_position = i\n",
    "    search_position = search_position.lower().replace(' ','+')\n",
    "\n",
    "# template = 'https://glints.com/id/opportunities/jobs/explore?'\n",
    "# url_params = 'keyword={}&country=ID&locationName={}' if search_position and location else 'keyword={}&country=ID&locationName=All+Cities%2FProvinces'\n",
    "\n",
    "    while True:\n",
    "        # 1. find using input job on list\n",
    "        # url = 'https://glints.com/id/opportunities/jobs/explore?keyword={}&country=ID&locationName=All+Cities%2FProvinces&page={}'.format(search_position,page)\n",
    "\n",
    "        # 2. find using category = computer information technology\n",
    "        url = 'https://glints.com/id/job-category/computer-information-technology?page={}'.format(page)\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        # if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        job_cards = soup.find('div', class_='JobCardsc__JobcardContainer-sc-hmqj50-0 iirqVR CompactOpportunityCardsc__CompactJobCardWrapper-sc-dkg8my-2 bMyejJ compact_job_card')\n",
    "                \n",
    "        for job_card in job_cards:\n",
    "            job_title = find_tag_value(job_card, 'h3', 'CompactOpportunityCardsc__JobTitle-sc-dkg8my-9 hgMGcy')\n",
    "            company_name = find_tag_value(job_card, 'a', 'CompactOpportunityCardsc__CompanyLink-sc-dkg8my-10 iTRLWx')\n",
    "            job_location = find_tag_value(job_card, 'span', 'CardJobLocation__StyledTruncatedLocation-sc-1by41tq-1 kEinQH')\n",
    "            work_place = find_tag_value(job_card, 'div', 'TagStyle-sc-r1wv7a-4 bJWZOt CompactOpportunityCardTags__Tag-sc-610p59-1 hncMah')\n",
    "            job_tags = job_cards.find_all('div', class_='TagStyle__TagContentWrapper-sc-r1wv7a-1 koGVuk')\n",
    "            job_tag_values = [tag.text for tag in job_tags]\n",
    "            years_experience = job_tag_values[2]\n",
    "            min_education = job_tag_values[3]\n",
    "            \n",
    "            salary_range = find_tag_value(job_card, 'span', 'CompactOpportunityCardsc__NotDisclosedMessage-sc-dkg8my-23 hivaYx')\n",
    "            if salary_range:\n",
    "                salary_range = 'Not Written'\n",
    "            else:\n",
    "                salary_range = find_tag_value(job_card, 'span', 'CompactOpportunityCardsc__SalaryWrapper-sc-dkg8my-29 gfPeyg')\n",
    "            \n",
    "            skill = find_tag_attr(job_card, 'card-info').replace('experience,logo,','')\n",
    "            job_id = find_tag_attr(job_card, 'id')\n",
    "            work_type = find_tag_attr(job_card, 'type')\n",
    "            category = find_tag_attr(job_card, 'category')\n",
    "            sub_category = find_tag_attr(job_card, 'sub-category')\n",
    "            role = find_tag_attr(job_card, 'role')\n",
    "\n",
    "            more_detail_link = 'https://glints.com'+ job_card.find('a', class_= 'CompactOpportunityCardsc__CardAnchorWrapper-sc-dkg8my-24 knEIai job-search-results_job-card_link').get('href')\n",
    "            # detail link request\n",
    "            response_detail = requests.get(more_detail_link, headers=headers)\n",
    "            soup_detail = BeautifulSoup(response_detail.content, 'html.parser')\n",
    "            posted_date = find_tag_value(soup_detail,'div','JobDescriptionsc__DescriptionContainer-sc-22zrgx-2 jCwTA-d')\n",
    "            print('posted_date:',posted_date)\n",
    "            job_description = find_tag_value(soup_detail,'div','JobDescriptionsc__DescriptionContainer-sc-22zrgx-2 jCwTA-d')\n",
    "\n",
    "            print(f\"Job Title: {job_title}\")\n",
    "            print(f\"Company Name: {company_name}\")\n",
    "            print(f\"Experience: {years_experience}\")\n",
    "            print(f\"Education: {min_education}\")\n",
    "            print(f\"Work Place: {work_place}\")\n",
    "            print(f\"Work Type: {work_type}\")\n",
    "            # print(f\"Posted Date: {posted_date}\")\n",
    "            print(f\"Salary: {salary_range}\")\n",
    "            print(f\"Detail Description: {job_description}\")\n",
    "            \n",
    "            data.append({\n",
    "                'job_title': job_title,\n",
    "                'company_name': company_name,\n",
    "                'job_location': job_location,\n",
    "                'work_place': work_place,\n",
    "                'salary_range': salary_range,\n",
    "                'more_detail_link': more_detail_link,\n",
    "                'job_id': job_id,\n",
    "                'work_type': work_type,\n",
    "                'workplace': work_place,\n",
    "                'years_experience': years_experience,\n",
    "                'min_education': min_education,\n",
    "                'category': category,\n",
    "                'sub_category': sub_category,\n",
    "                'role': role\n",
    "            })\n",
    "            \n",
    "        page += 1\n",
    "        next_button = soup.find('a', class_='pagination__link pagination__next')\n",
    "        if not next_button:\n",
    "            print('No more pages to fetch')\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(f\"Failed to fetch URL: {url}\")\n",
    "            break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# custom_name = f'list_of_jobs_glints_1.csv'\n",
    "# file_path = os.path.join(script_dir, custom_name)\n",
    "# df.to_csv(file_path, index=False, encoding='utf-8')\n",
    "\n",
    "# # connect to mongodb\n",
    "\n",
    "# import pymongo\n",
    "# from pymongo import MongoClient\n",
    "\n",
    "# # connect to mongodb\n",
    " \n",
    "# client = MongoClient('mongodb://localhost:27017/')\n",
    "# db = client['jobs']\n",
    "# collection = db['glints']\n",
    "\n",
    "# # convert dataframe to dictionary\n",
    "# data_dict = df.to_dict(\"records\")\n",
    "\n",
    "# # insert data to mongodb\n",
    "# collection.insert_many(data_dict)\n",
    "\n",
    "# # check data in mongodb\n",
    "# cursor = collection.find({})\n",
    "# for document in cursor:\n",
    "#     print(document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging 2 CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('list_of_jobs_glints.csv')\n",
    "df2 = pd.read_csv('list_of_jobs_glints_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.concat([df, df2])\n",
    "merged_df.to_csv('merged_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Merged File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate based on job_id\n",
    "merged_df = merged_df.drop_duplicates(subset='job_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file = pd.read_csv('merged_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Company Name Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(job_dataset, column_name):\n",
    "    corpus = []\n",
    "    for i in range(0, len(job_dataset)):\n",
    "        text = re.sub(r'[.\"]', '', job_dataset[column_name][i])\n",
    "        text = text.upper()\n",
    "        text = text.split()\n",
    "        text = ' '.join(text)\n",
    "        corpus.append(text)\n",
    "\n",
    "    job_dataset[column_name] = corpus\n",
    "    return job_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_column(merged_file,'company_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file['role'].value_counts().to_csv('role.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file['sub_category'].value_counts().to_csv('sub_cat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
